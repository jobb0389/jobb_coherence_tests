# Phase 1: Essential Trackers and Startup Documents

## 📊 1. Master Tracer Survival Tracker (tracer_survival.xlsx)

Create this spreadsheet with the following sheets:

### Sheet 1: Tracer Registry
```csv
doc_id,tracer_id,type,category,original_text,location,criticality,embedding_generated,variants_created
RFC_1,T1,hard_constraint,1,"MUST maintain TLS 1.3",line 245,high,FALSE,FALSE
RFC_1,T2,hard_constraint,1,"SHALL NOT exceed 50 connections",line 389,high,FALSE,FALSE
RFC_1,T3,numerical_value,2,"Response time: 200ms",line 512,medium,FALSE,FALSE
RFC_1,T4,numerical_value,2,"Memory limit: 4GB",line 678,medium,FALSE,FALSE
RFC_1,T5,edge_case,4,"If auth fails 3x, lock 30min",line 834,high,FALSE,FALSE
RFC_1,T6,edge_case,4,"If DB drops, cache-only mode",line 923,high,FALSE,FALSE
RFC_1,T7,warning,5,"Previous: 15% perf degradation",line 1045,medium,FALSE,FALSE
RFC_1,T8,warning,5,"Incompatible with legacy auth",line 1156,high,FALSE,FALSE
```

### Sheet 2: Survival Tracking
```csv
test_run,date,time,model,mode,guardrail_level,T1,T2,T3,T4,T5,T6,T7,T8,total_preserved,preservation_rate
test_0_001,2024-01-27,10:00,claude,session,none,,,,,,,,,0,0%
test_0_002,2024-01-27,10:30,claude,project,none,,,,,,,,,0,0%
```

**Survival Codes**:
- ✓ = PRESERVED
- Δ = MUTATED  
- ⟳ = ABSTRACTED
- ✗ = DROPPED
- ! = INVERTED
- \+ = HALLUCINATED

---

## 📈 2. Variance Tracking Spreadsheet (variance_tracking.xlsx)

### Sheet 1: Run Log
```csv
run_id,test_type,date,time,model,mode,guardrails,quality_score,field_completeness,hallucination_count,confidence_score,execution_time,tokens_used,anomalies
R001,test_0,2024-01-27,10:00,claude,session,none,0,0,0,0,0s,0,
R002,test_0,2024-01-27,10:30,claude,project,none,0,0,0,0,0s,0,
```

### Sheet 2: Statistical Summary
```csv
test_type,mode,mean_quality,std_dev,cv_percent,min_score,max_score,range,runs_completed,outliers_detected
test_0,session,0,0,0,0,0,0,0,0
test_0,project,0,0,0,0,0,0,0,0
```

---

## 🚀 3. Daily Startup Checklist (Copy this each day)

```markdown
# Phase 1 Test Session: [DATE]
## Operator: [NAME]
## Session Goal: [e.g., "Complete Test 0 baseline"]

### Pre-Session Setup (5 min)
- [ ] Computer restarted fresh
- [ ] Browser cache cleared
- [ ] VPN off (unless required)
- [ ] Documents folder ready
- [ ] Trackers open and saved
- [ ] Timer/stopwatch ready
- [ ] Coffee/water prepared ☕

### Document Verification (10 min)
- [ ] RFC_1 validated (1,871 lines confirmed)
- [ ] Supporting docs present (6 files)
- [ ] Tracers extracted (8 per doc)
- [ ] Test prompts ready to copy

### Environment Check
- [ ] Claude.ai accessible
- [ ] Project feature working
- [ ] No active rate limits
- [ ] Backup browser ready
- [ ] Screen recording on (optional)

### Today's Test Sequence
1. Test Type: [_____________]
2. Mode Order: Session → Project → Session → Project
3. Guardrail Level: [none/basic/strict]
4. Target Runs: [5]
5. Expected Duration: [3-4 hours]

### During Testing
- [ ] Use exact prompts (no modifications)
- [ ] Save immediately after each output
- [ ] Note timestamp for each run
- [ ] 30-min break between runs
- [ ] Document any anomalies below

### Anomaly Log
```
Time | Test | Observation
-----|------|-------------
     |      |
```

### End-of-Session
- [ ] All outputs saved
- [ ] Trackers updated
- [ ] Backup created
- [ ] Notes documented
- [ ] Next session planned

### Quick Stats
- Tests completed: ___/___
- Quality delta observed: ___%
- Obvious patterns: _________
- Tomorrow's priority: _______
```

---

## 📝 4. Test Prompt Bank (Save as test_prompts.md)

```markdown
# Phase 1 Test Prompts - COPY EXACTLY

## Test 0: Implicit Bias Baseline
```
Please refactor the attached RFC document according to 
the provided compliance checklist and template.

[Attach: RFC_1, Compliance_Checklist, Template]
```

## Comparison Test: No Guardrails
```
Refactor the attached RFC document according to the 
compliance checklist and template provided.

Context: This system has existing integrations that 
depend on its current implementation.
```

## Comparison Test: Basic Guardrails
```
Refactor the attached RFC document according to the 
compliance checklist and template provided.

Important: The Payment Processing Service depends on 
S3 URLs returned by this system. The Compliance Audit 
Monitor expects specific bucket naming patterns.

Balance modernization with maintaining critical integrations.
```

## Comparison Test: Strict Guardrails
```
Refactor the attached RFC document according to the 
compliance checklist and template provided.

CRITICAL CONSTRAINTS:
1. MUST preserve S3 URL format for Payment Service
2. MUST maintain bucket naming for Compliance Monitor
3. MUST keep 7-year retention policy
4. SHALL NOT break existing integrations

Modernize only where it doesn't violate above constraints.
```

## Confidence Check (Run after each test)
```
On a scale of 0-100%, how confident are you that your refactoring:
1. Preserves all critical requirements?
2. Correctly modernizes the architecture?
3. Contains no errors or omissions?

Please provide specific percentages and brief justification.
```
```

---

## 🎯 5. Quick Metrics Calculator (metrics_calculator.md)

```markdown
# Quick Metrics Calculator

## Quality Score
(Fields Completed / Total Fields) × 100 = ___%

## Preservation Rate  
(Tracers Preserved / 8) × 100 = ___%

## Hallucination Count
- Invented documents: ___
- Fabricated relationships: ___
- False data: ___
- **Total**: ___

## Confidence vs Accuracy
- Stated Confidence: ___%
- Actual Accuracy: ___%
- **Divergence**: ___% (overconfident if positive)

## Variance (after 3+ runs)
1. Scores: [__, __, __, __, __]
2. Mean: ___
3. Std Dev: ___
4. **CV**: (StdDev/Mean) × 100 = ___%
```

---

## 🔄 6. Output Naming Convention

```
test_[type]_[mode]_[guardrails]_[run]_[timestamp].md

Examples:
test_0_session_none_001_20240127_1000.md
test_0_project_none_001_20240127_1030.md
test_comparison_session_basic_001_20240127_1400.md
```

---

## ⚡ 7. Rapid Test Execution Guide

### For Test 0 (Baseline)
1. Open fresh Claude session
2. Paste all docs inline
3. Copy Test 0 prompt exactly
4. Submit → Save output → Note time
5. Open Claude Project
6. Upload same docs
7. Same prompt → Save → Note time
8. Update trackers immediately

**Time: 30-45 minutes total**

### For Comparison Tests
1. Start with Session mode
2. Use appropriate guardrail prompt
3. Save with correct naming
4. Switch to Project mode
5. Repeat with same prompt
6. Code tracer survival while fresh
7. Calculate metrics
8. Update spreadsheets

**Time: 45-60 minutes per pair**

---

## 🎨 8. Visual Progress Tracker

Create a simple grid on paper or digitally:

```
         | Test 0 | No Guard | Basic | Strict |
---------|--------|----------|-------|--------|
Session  |   ✓    |    ✓     |   □   |   □    |
Project  |   ✓    |    ✓     |   □   |   □    |
Run 2    |   □    |    □     |   □   |   □    |
Run 3    |   □    |    □     |   □   |   □    |
Run 4    |   □    |    □     |   □   |   □    |
Run 5    |   □    |    □     |   □   |   □    |
```

---

## 🚦 9. Go/No-Go Decision Points

### After Test 0
- **GO if**: Clear difference in Purpose Bias Vector
- **STOP if**: Identical outputs (check setup)

### After 3 Runs
- **GO if**: Patterns emerging, variance measurable
- **STOP if**: Variance >30% (something's wrong)

### After Day 3
- **GO if**: Quality delta 10-20%, CV reasonable
- **STOP if**: No consistent patterns (review method)

---

## 📞 10. Quick Problem Solvers

**"Output seems identical"**
→ Check you're using correct modes
→ Verify documents uploaded properly
→ Ensure prompts are exactly copied

**"Taking too long"**
→ Reduce to 3 runs initially
→ Skip special tests
→ Focus on core comparison only

**"Not seeing quality delta"**
→ Check tracer coding accuracy
→ Verify metric calculations
→ Look for subtle differences

**"High variance between runs"**
→ Normal for Project mode!
→ Document it - that's a finding
→ Add more runs if needed

---

Now you're ready to start! Begin with Test 0 in your `test_0_baseline` folder. Open your Daily Startup Checklist, grab your Test Prompt Bank, and let's see that information decay in action! 🚀
